{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Juniper BOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries and files\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "from os import path\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### moxa.eworldme.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\\\n",
    "# Industrial Network Infrastructure/Secure Routers/Secure Routers/EDR-810 Series\n",
    "source = \"D://UAE//moxa-eworldme//\"\n",
    "category = []\n",
    "Brands = []\n",
    "currency = []\n",
    "prices = []\n",
    "SKUS = []\n",
    "descriptions = []\n",
    "product_images = []\n",
    "product_prices = []\n",
    "prod_model_num = []\n",
    "listToStr = []\n",
    "\n",
    "option = Options()\n",
    "option.add_argument(\"--disable-infobars\")\n",
    "option.add_argument(\"start-maximized\")\n",
    "option.add_argument(\"--disable-extensions\")\n",
    "\n",
    "# Pass the argument 1 to allow and 2 to block\n",
    "option.add_experimental_option(\"prefs\", { \n",
    "    \"profile.default_content_setting_values.notifications\": 1 \n",
    "})\n",
    "option.headless = True\n",
    "driver = webdriver.Chrome(chrome_options=option, executable_path=\"./chromedriver\")\n",
    "\n",
    "# link = \"https://moxa.eworldme.com/MOXA-Industrial-Network-Infrastructure/MOXA-Secure-Routers/MOXA-Secure-Routers-1/MOXA-EDR-810-Series/MOXA-EDR-810-2GSFP-Industrial-Secure-Router\"\n",
    "with open(\"D://UAE//moxa-eworldme//upload_files//Industrial Network Infrastructure.txt\", 'r', encoding= 'utf-8') as fp:\n",
    "    url = fp.readlines()\n",
    "    for link in url:\n",
    "        driver.get(link)\n",
    "        driver.implicitly_wait(30)\n",
    "        time.sleep(60)\n",
    "        page = driver.find_elements_by_class_name('site-wrapper')\n",
    "        for page in page:\n",
    "            soup = BeautifulSoup(page.get_attribute('innerHTML'), 'html.parser')\n",
    "        #     print(soup.prettify()) \n",
    "            breadcrumbs = soup.select('.breadcrumb')\n",
    "        #     print(breadcrumbs)\n",
    "            for sub_list in breadcrumbs:\n",
    "                c_list = sub_list.text\n",
    "                category.append(c_list.strip().replace('\\n',' '))\n",
    "\n",
    "            details = soup.select('#product,.product-details')\n",
    "        #     print(details)\n",
    "            for descript in details:\n",
    "                try:\n",
    "                    short = descript.select('.title,.page-title')\n",
    "                    for sh in short:\n",
    "                        descriptions.append(sh.text)\n",
    "                except Exception as e:\n",
    "                    sh = None\n",
    "            for p in details:\n",
    "                try:\n",
    "                    price = p.select('.product-price')\n",
    "                    for pr in price:\n",
    "                        product_prices.append(pr.text)\n",
    "                except Exception as e:\n",
    "                    p = None\n",
    "            for m in details:\n",
    "                try:\n",
    "                    model = m.select('.product-model')\n",
    "                    for m_no in model:\n",
    "                        prod_model_num.append(m_no.text)\n",
    "                except Exception as e:\n",
    "                    m = None\n",
    "            img = soup.select('.product-image, .direction-vertical, .position-left')\n",
    "            try:\n",
    "                for i in img:\n",
    "                    g = i.select('swiper-slide, .swiper-slide-visible')\n",
    "                    for images in g:\n",
    "                        link = images.find('img')['src']\n",
    "                        product_images.append(link)\n",
    "            except Exception as e:\n",
    "                img = None\n",
    "    fp.close()\n",
    "# SKU's\n",
    "for sku in prod_model_num:\n",
    "    PID = sku.split()[1]\n",
    "    SKUS.append(PID)\n",
    "# BRNDS\n",
    "for brand in category:\n",
    "    br = brand.split()[2:4]\n",
    "#     using list comprehension \n",
    "    listToStr = ' '.join(map(str, br)) \n",
    "    Brands.append(listToStr)\n",
    "\n",
    "# Currrency\n",
    "for price in product_prices:\n",
    "    pr = price.split()[0]\n",
    "    currency.append(pr)\n",
    "\n",
    "# Price Value\n",
    "for price in product_prices:\n",
    "    pr = price.split()[1]\n",
    "    prices.append(pr)\n",
    "# print(\"Brands:\", brand.split()[:3])\n",
    "#  br = brand.split()[:3]\n",
    "#  Brands.append(br)\n",
    "# print(Brands)\n",
    "# using list comprehension \n",
    "# listToStr = ' '.join(map(str, s)) \n",
    "# print(listToStr)\n",
    "#data = {'SKUs':prod_model_num, 'Category': category, 'Brand':category[:3],'Short Description':descriptions, 'Currency':product_prices[0], 'Product Price':product_prices[1],'Product Images':product_images,}\n",
    "\n",
    "data = {'SKUs':SKUS, 'Brand':Brands, 'Category': category, 'Short Description':descriptions, 'Product Images':product_images, 'Products Prices':product_prices, 'Product Currency': currency, 'Product Prices':prices,}\n",
    "print(data)\n",
    "\n",
    "df = pd.DataFrame.from_dict(data, orient='index')\n",
    "df = df.transpose()\n",
    "print(df)\n",
    "print(\"Got these many results:\",df.shape)\n",
    "    \n",
    "file_name = input(\"Name of the file using CSV extention e.g; master files.csv: \")\n",
    "df.to_csv(source+\"\"+file_name,index=False)\n",
    "# print(category)\n",
    "# print(descriptions)\n",
    "# print(\"Currency \",currency, \"\\n\",\"Price is\", prices)\n",
    "# print(product_prices)\n",
    "#print(prod_model_num) product-image direction-vertical position-left\n",
    "# print(product_images)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "option = Options()\n",
    "option.add_argument(\"--disable-infobars\")\n",
    "option.add_argument(\"start-maximized\")\n",
    "option.add_argument(\"--disable-extensions\")\n",
    "\n",
    "# Pass the argument 1 to allow and 2 to block\n",
    "option.add_experimental_option(\"prefs\", { \n",
    "    \"profile.default_content_setting_values.notifications\": 1 \n",
    "})\n",
    "option.headless = True\n",
    "driver = webdriver.Chrome(chrome_options=option, executable_path=\"D://chromedriver\")\n",
    "\n",
    "link = \"https://moxa.eworldme.com/MOXA-Industrial-Edge-Connectivity/MOXA-IP-Cameras-Video-Servers/MOXA-IP-Cameras/VPort-15-M12-Series/MOXA-VPort-15-M12-NTSC-Dome-IP-Camera\"\n",
    "driver.get(link)\n",
    "driver.implicitly_wait(10)\n",
    "time.sleep(30)\n",
    "page = driver.find_elements_by_class_name('site-wrapper')\n",
    "for pages in page:\n",
    "    soup = BeautifulSoup(pages.get_attribute('innerHTML'), 'html.parser')\n",
    "    print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping w/Python\n",
    "## free code camp \n",
    "###### link: https://www.youtube.com/watch?v=XVv6mJpFOb0&t=93s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "# ChromeOptions options = new ChromeOptions();\n",
    "# Counter\n",
    "counter = int(input('Make a threads of bot more than 1:'))\n",
    "while counter >= 1:\n",
    "    option = Options()\n",
    "    option.add_argument(\"--disable-infobars\")\n",
    "    option.add_argument(\"start-maximized\")\n",
    "    option.add_argument(\"--disable-extensions\")\n",
    "\n",
    "    # Pass the argument 1 to allow and 2 to block\n",
    "    option.add_experimental_option(\"prefs\", { \n",
    "        \"profile.default_content_setting_values.notifications\": 1 \n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(chrome_options=option, executable_path=\"./chromedriver\")\n",
    "\n",
    "    source = \"D://ormusa//JUNIPER FILES//\"\n",
    "    skus = []\n",
    "    brands = []\n",
    "    prod_ID = []\n",
    "    sh_descrip = []\n",
    "    long_descrip = []\n",
    "    old_prices = []\n",
    "    sale_prices = []\n",
    "    Images = []\n",
    "    category = []\n",
    "\n",
    "    urls = open(\"link.txt\", 'r', encoding= 'utf-8')\n",
    "    url = urls.readlines()\n",
    "    for link in url:\n",
    "        driver.get(link)\n",
    "        driver.implicitly_wait(30)\n",
    "        \n",
    "        breadcrumb = driver.find_elements_by_class_name('main')\n",
    "        for breadcrumbs in breadcrumb:\n",
    "            soup = BeautifulSoup(breadcrumbs.get_attribute('innerHTML'), 'html.parser')\n",
    "            cate_list = soup.select('.breadcrumbs')\n",
    "#             print(cate_list)\n",
    "            for sub_list in cate_list:\n",
    "                c_list = sub_list.text\n",
    "                category.append(c_list.replace('\\n',''))\n",
    "#                 c = c_list.replace('\\n','')\n",
    "#                 print(c)\n",
    "                \n",
    "        all_sku = driver.find_elements_by_class_name('product-view')\n",
    "    \n",
    "        for sku in all_sku:\n",
    "            soup = BeautifulSoup(sku.get_attribute('innerHTML'),'html.parser')\n",
    "            #print(soup.prettify()) \n",
    "        #https://www.router-switch.com/juniper-price.html\n",
    "            detail = soup.select('.product-shop')\n",
    "#             print(detail.prettify())\n",
    "            for sku in detail:\n",
    "                try:\n",
    "                    h1 = sku.select('.product-name')\n",
    "                    for h in h1:\n",
    "                        pid = h.find('h1').text\n",
    "                        sku = h.find('span', itemprop=\"sku\").text\n",
    "                        brand = h.find('span', itemprop=\"brand\").text\n",
    "                        skus.append(sku)\n",
    "                        brands.append(brand)\n",
    "                        prod_ID.append(pid)\n",
    "                except Exception as e:\n",
    "                    h1 = None\n",
    "            for desc in detail:\n",
    "                try:\n",
    "                    txt = desc.select(\"table > .data-table,.product-data-table\")\n",
    "                    for d in txt:\n",
    "                        descrip = d.find(\"td\", itemprop=\"description\").text\n",
    "#                         print(\"Short Description: \",descrip)\n",
    "                        sh_descrip.append(descrip)\n",
    "                        try:\n",
    "                            op = d.find('td', {'class':'listprice'}).find('span').text\n",
    "#                             print(\"OLD Prices\",op)\n",
    "                            old_prices.append(op)\n",
    "                        except Exception as e:\n",
    "                            op = None\n",
    "                        try:\n",
    "                            sp = d.find('td', {'class': 'saleprice'}).find('span',{'class':'regular-price'}).find('span').text\n",
    "#                             print(\"SALE Prices\",sp)\n",
    "                            sale_prices.append(sp)\n",
    "                        except Exception as e:\n",
    "                            sp = None\n",
    "                except Exception as e:\n",
    "                    desc = None\n",
    "                    \n",
    "#                     LONG DESCRIPTION\n",
    "            details = soup.select(\"dd > .tab-container, .dd-specification\")\n",
    "            for long_desc in details:\n",
    "                try:\n",
    "                    descp = long_desc.find(\"div\", {'class', 'tab-content'})\n",
    "                    #print(descp)\n",
    "                    long_descrip.append(descp)\n",
    "                except Exception as e:\n",
    "                    descp = None\n",
    "#     print(skus) product-img-box                   \n",
    "        for img in all_sku:\n",
    "            soup = BeautifulSoup(img.get_attribute('innerHTML'),'html.parser')\n",
    "#             print(soup.prettify())\n",
    "            i = soup.select('div > .product-image' )\n",
    "            for images in i:\n",
    "                link = images.find('a')['href']\n",
    "                Images.append(link)\n",
    "#     print(Images)    \n",
    "    data = {'SKUs':skus, 'Category List': category, 'Product ID':prod_ID, 'Brand':brands,'Description':sh_descrip, 'OLD Price':old_prices, 'SALE Price':sale_prices, 'Long descriptions':long_descrip,'Images':Images,}\n",
    "\n",
    "    df = pd.DataFrame.from_dict(data, orient='index')\n",
    "    df = df.transpose()\n",
    "    print(df)\n",
    "    print(\"Got these many results:\",df.shape)\n",
    "    \n",
    "    file_name = input(\"Name of the file using CSV extention e.g; master files.csv: \")\n",
    "    df.to_csv(source+\"\"+file_name,index=False)\n",
    "\n",
    "    counter = counter - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv ('ramzan.csv', sep=\",\")\n",
    "# df = pd.DataFrame(data)\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cisco firewalls router-switches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make a threads of bot more than 1:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DAY USER\\AppData\\Local\\Temp\\ipykernel_8476\\1665904415.py:16: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(chrome_options=option, executable_path=\"C://Users//DAY USER//Documents//Scapper//chromedriver\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provide your links file path with file name *only accept TXT files : C://Users//DAY USER//Documents//Scapper//Huawei.txt\n",
      "   SKUs                                           Category Product ID Brand  \\\n",
      "0  None                                      Home      ...       None  None   \n",
      "1  None                                      Home      ...       None  None   \n",
      "2  None                                      Home      ...       None  None   \n",
      "3  None                                      Home      ...       None  None   \n",
      "\n",
      "  Description OLD Price SALE Price Long descriptions Images  \n",
      "0        None      None       None              None   None  \n",
      "1        None      None       None              None   None  \n",
      "2        None      None       None              None   None  \n",
      "3        None      None       None              None   None  \n",
      "Got these many results: (4, 9)\n",
      "Name of the file using CSV extention e.g; master files.csv: huwaii\n"
     ]
    }
   ],
   "source": [
    "#################################\n",
    "# ChromeOptions options = new ChromeOptions();\n",
    "# Counter\n",
    "counter = int(input('Make a threads of bot more than 1:'))\n",
    "while counter >= 1:\n",
    "    option = Options()\n",
    "    option.add_argument(\"--disable-infobars\")\n",
    "    option.add_argument(\"start-maximized\")\n",
    "    option.add_argument(\"--disable-extensions\")\n",
    "\n",
    "    # Pass the argument 1 to allow and 2 to block\n",
    "    option.add_experimental_option(\"prefs\", {\n",
    "        \"profile.default_content_setting_values.notifications\": 1\n",
    "    })\n",
    "    option.headless = True\n",
    "    driver = webdriver.Chrome(chrome_options=option, executable_path=\"C://Users//DAY USER//Documents//Scapper//chromedriver\")\n",
    "\n",
    "    source = \"C://Users//DAY USER//Documents//Scapper//\"\n",
    "    skus = []\n",
    "    category = []\n",
    "    brands = []\n",
    "    prod_ID = []\n",
    "    sh_descrip = []\n",
    "    long_descrip = []\n",
    "    old_prices = []\n",
    "    sale_prices = []\n",
    "    Images = []\n",
    "    \n",
    "    dir_path = input(\"Provide your links file path with file name *only accept TXT files : \")\n",
    "    urls = open(dir_path, 'r', encoding='utf-8')\n",
    "    url = urls.readlines()\n",
    "    for link in url:\n",
    "        driver.get(link)\n",
    "#         print(link)\n",
    "        driver.implicitly_wait(60)\n",
    "\n",
    "        breadcrumb = driver.find_elements_by_class_name('main')\n",
    "        for breadcrumbs in breadcrumb:\n",
    "            soup = BeautifulSoup(breadcrumbs.get_attribute('innerHTML'), 'html.parser')\n",
    "            cate_list = soup.select('.breadcrumbs')\n",
    "            #             print(cate_list)\n",
    "            for sub_list in cate_list:\n",
    "                c_list = sub_list.text\n",
    "                category.append(c_list.replace('\\n', ''))\n",
    "        #                 c = c_list.replace('\\n','')\n",
    "        #                 print(c)\n",
    "\n",
    "        all_sku = driver.find_elements_by_class_name('product-view')\n",
    "\n",
    "        for sku in all_sku:\n",
    "            soup = BeautifulSoup(sku.get_attribute('innerHTML'), 'html.parser')\n",
    "            # print(soup.prettify())\n",
    "            # https://www.router-switch.com/juniper-price.html\n",
    "            detail = soup.select('.product-shop')\n",
    "            #             print(detail.prettify())\n",
    "            for sku in detail:\n",
    "                try:\n",
    "                    h1 = sku.select('.product-name')\n",
    "#                     print('Product ID', h1)\n",
    "                    for h in h1:\n",
    "                        try:\n",
    "                            pid = h.find('h1', itemprop=\"name\").text\n",
    "                            prod_ID.append(pid)\n",
    "\n",
    "                        except Exception as e:\n",
    "                            pid = None\n",
    "                        try:\n",
    "                            sku = h.find('span', itemprop=\"sku\").text\n",
    "                            skus.append(sku)\n",
    "\n",
    "                        except Exception as e:\n",
    "                            sku = None\n",
    "                        try:\n",
    "\n",
    "                            brand = h.find('span', itemprop=\"brand\").text\n",
    "                            brands.append(brand)\n",
    "                        except Exception as e:\n",
    "                            brand = None\n",
    "\n",
    "                    # print( skus + brands + prod_ID)\n",
    "                except Exception as e:\n",
    "                    h1 = None\n",
    "            for desc in detail:\n",
    "                try:\n",
    "                    txt = desc.select(\"table > .data-table,.product-data-table\")\n",
    "                    for d in txt:\n",
    "                        descrip = d.find(\"td\", itemprop=\"description\").text\n",
    "                        #                         print(\"Short Description: \",descrip)\n",
    "                        sh_descrip.append(descrip)\n",
    "                        try:\n",
    "                            op = d.find('td', {'class': 'listprice'}).find('span').text\n",
    "#                             print(\"OLD Prices\",op)\n",
    "                            old_prices.append(op)\n",
    "                        except Exception as e:\n",
    "                            op = None\n",
    "                        try:\n",
    "                            sp = d.find('td', {'class': 'saleprice'}).find('span', {'class': 'regular-price'}).find(\n",
    "                                'span').text\n",
    "#                             print(\"SALE Prices\\n\",sp)\n",
    "#                             print(\"===============\")\n",
    "                            sale_prices.append(sp)\n",
    "                        except Exception as e:\n",
    "                            sp = None\n",
    "                except Exception as e:\n",
    "                    desc = None\n",
    "\n",
    "            #                     LONG DESCRIPTION\n",
    "            details = soup.select(\"dd > .tab-container, .dd-specification\")\n",
    "            for long_desc in details:\n",
    "                try:\n",
    "                    descp = long_desc.find(\"div\", {'class', 'tab-content'})\n",
    "                    # print(descp)\n",
    "                    long_descrip.append(descp)\n",
    "                except Exception as e:\n",
    "                    descp = None\n",
    "        #     print(skus) product-img-box\n",
    "        for img in all_sku:\n",
    "            soup = BeautifulSoup(img.get_attribute('innerHTML'), 'html.parser')\n",
    "            #             print(soup.prettify())\n",
    "            try:\n",
    "                i = soup.select('div > .product-image')\n",
    "                for images in i:\n",
    "                    link = images.find('a')['href']\n",
    "#                     print(link + '\\n')\n",
    "                    Images.append(link)\n",
    "            except Exception as e:\n",
    "                i = None\n",
    "#     print(Images)\n",
    "    \n",
    "    data = {'SKUs': skus, 'Category': category, 'Product ID': prod_ID, 'Brand': brands, 'Description': sh_descrip, 'OLD Price': old_prices,\n",
    "            'SALE Price': sale_prices, 'Long descriptions': long_descrip, 'Images': Images, }\n",
    "\n",
    "    df = pd.DataFrame.from_dict(data, orient='index')\n",
    "    df = df.transpose()\n",
    "    print(df)\n",
    "    print(\"Got these many results:\", df.shape)\n",
    "\n",
    "    file_name = input(\"Name of the file using CSV extention e.g; master files.csv: \")\n",
    "    df.to_csv(source + \"\" + file_name, index=False)\n",
    "\n",
    "    counter = counter - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rough code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = []\n",
    "urls = open(\"ramzan.txt\", 'r', encoding = 'utf-8')\n",
    "url = urls.readlines()\n",
    "print(url)\n",
    "for link in url:\n",
    "    merge.append(link)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<li class=\"clearfix job-bx wht-shd-bx\">\n",
      "<header class=\"clearfix\">\n",
      "<!--\n",
      "-->\n",
      "<!-- -->\n",
      "<h2>\n",
      "<a href=\"https://www.timesjobs.com/job-detail/python-pure-tech-codex-private-limited-pune-2-to-3-yrs-jobid-OHwfF0d6EhNzpSvf__PLUS__uAgZw==&amp;source=srp\" onclick=\"logViewUSBT('view','66840090','rest  ,  python  ,  database  ,  django  ,  debugging  ,  mongodb','Pune','2 - 3','IT Software : Software Products &amp; Services','1' )\" target=\"_blank\">\n",
      "<strong class=\"blkclor\">Python</strong></a> </h2>\n",
      "<h3 class=\"joblist-comp-name\">\r\n",
      "    Pure Tech Codex Private Limited\r\n",
      "    \r\n",
      "    </h3>\n",
      "</header>\n",
      "<ul class=\"top-jd-dtl clearfix\">\n",
      "<li><i class=\"material-icons\">card_travel</i>2 - 3 yrs</li>\n",
      "<li>\n",
      "<i class=\"material-icons\">location_on</i>\n",
      "<span title=\"Pune\">Pune</span>\n",
      "</li>\n",
      "</ul>\n",
      "<ul class=\"list-job-dtl clearfix\">\n",
      "<li>\n",
      "<label>Job Description:</label>\r\n",
      "Job Description: 2 to 3 Years experience in Python.Expert in Python ,  with knowledge of at least one Python web framework  Flask ,  Django etc.Expert in server programming.Go... <a href=\"https://www.timesjobs.com/job-detail/python-pure-tech-codex-private-limited-pune-2-to-3-yrs-jobid-OHwfF0d6EhNzpSvf__PLUS__uAgZw==&amp;source=srp\" target=\"_blank\">More Details</a>\n",
      "</li>\n",
      "<li>\n",
      "<label>KeySkills:</label>\n",
      "<span class=\"srp-skills\">\r\n",
      "      \r\n",
      "          rest  ,  <strong class=\"blkclor\">python</strong>  ,  database  ,  django  ,  debugging  ,  mongodb\r\n",
      "        \r\n",
      "      </span> </li>\n",
      "<!--\r\n",
      "            <li>\r\n",
      "              <i class=\"material-icons\">location_on</i>\r\n",
      "              Pune\r\n",
      "              </li>\r\n",
      "-->\n",
      "</ul>\n",
      "<div class=\"list-job-bt clearfix\">\n",
      "<div class=\"list-action\">\n",
      "<div class=\"applied-dtl clearfix\" id=\"showPostApplyData_66840090\">\n",
      "<a class=\"waves-effect waves-light btn\" href=\"javascript:callExtJobApply('66840090','adId=OHwfF0d6EhNzpSvf__PLUS__uAgZw==&amp;compName=Career Progress Consultants','TJPFSRP');\" onclick=\"trackClickEvent('View_AND_Apply_SRP','from_srp_externalJobs');logViewUSBT('apply','66840090','rest  ,  python  ,  database  ,  django  ,  debugging  ,  mongodb','Pune','2 - 3','IT Software : Software Products &amp; Services','1')\">Apply</a>\n",
      "<span class=\"jobs-status clearfix\">\n",
      "<!--\r\n",
      "       <i class=\"material-icons trnding-up\" title=\"Recently posted job, Recruiter is actively looking for candidates\">check_circle</i>\r\n",
      "        \r\n",
      "-->\n",
      "</span>\n",
      "<span class=\"sim-posted\">\n",
      "<span>Posted few days ago</span>\n",
      "</span>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</li>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "\n",
    "html_text = requests.get('https://www.timesjobs.com/candidate/job-search.html?searchType=personalizedSearch&from=submit&txtKeywords=python&txtLocation=')\n",
    "# print(html_text)\n",
    "soup = bs(html_text.content, features=\"html\")\n",
    "jobs_list = soup.find('li', class_ = 'clearfix job-bx wht-shd-bx')\n",
    "print(jobs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## youtube bot with selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import platform\n",
    "# from termcolor import colored\n",
    "# from colorama import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def driverOS(value):\n",
    "    version = platform.system()\n",
    "    options = Options()\n",
    "    options.headless = value\n",
    "    if version == \"Windows\":\n",
    "        driver = webdriver.Chrome(executable_path=\"./chromedriver.exe\", chrome_options=options)\n",
    "    \n",
    "    return driver\n",
    "\n",
    "\n",
    "def login_gmail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Router switch BS4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make a threads of bot more than 1:1\n",
      "Page Connection code:  200\n",
      "['                                    Home                                                                    Firewalls                                                                    Cisco Firewalls                                                                    Cisco ASA 5500 Series                                ASA5512-K9']\n",
      "   SKUs                                           Category Product ID Brand  \\\n",
      "0  None                                      Home      ...       None  None   \n",
      "\n",
      "  Description OLD Price SALE Price Long descriptions Images  \n",
      "0        None      None       None              None   None  \n",
      "Got these many results: (1, 9)\n"
     ]
    }
   ],
   "source": [
    "#################################\n",
    "# ChromeOptions options = new ChromeOptions();\n",
    "# Counter\n",
    "counter = int(input('Make a threads of bot more than 1:'))\n",
    "while counter >= 1:\n",
    "#     option = Options()\n",
    "#     option.add_argument(\"--disable-infobars\")\n",
    "#     option.add_argument(\"start-maximized\")\n",
    "#     option.add_argument(\"--disable-extensions\")\n",
    "\n",
    "#     # Pass the argument 1 to allow and 2 to block\n",
    "#     option.add_experimental_option(\"prefs\", {\n",
    "#         \"profile.default_content_setting_values.notifications\": 1\n",
    "#     })\n",
    "#     # option.headless = True\n",
    "#     driver = webdriver.Chrome(chrome_options=option, executable_path=\"./chromedriver\")\n",
    "\n",
    "    source = \"D://ormusa//Cisco Firewalls//\"\n",
    "    skus = []\n",
    "    category = []\n",
    "    brands = []\n",
    "    prod_ID = []\n",
    "    sh_descrip = []\n",
    "    long_descrip = []\n",
    "    old_prices = []\n",
    "    sale_prices = []\n",
    "    Images = []\n",
    "\n",
    "    url= 'https://www.router-switch.com/asa5512-k9-p-4613.html'\n",
    "    \n",
    "    # Set headers\n",
    "    headers = requests.utils.default_headers()\n",
    "    headers.update({ \"User-Agent\":\"Mozilla/5.0 (Macintosh; Intel Mac OSX 10_14_3) AppleWebKit/537.36 (KHTML, like Gecko)Chrome/71.0.3578.98 Safari/537.36\", \"Accept\":\"text/html,application/xhtml+xml,application/xml; q=0.9,image/webp,image/apng,*/*;q=0.8\"})\n",
    "\n",
    "    page = requests.get(url, headers=headers, timeout=60)\n",
    "    print(\"Page Connection code: \",page.status_code)\n",
    "#         driver.implicitly_wait(60)\n",
    "\n",
    "#     soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    soup = BeautifulSoup(page.text, 'lxml')\n",
    "\n",
    "#         print(soup.prettify())\n",
    "        \n",
    "    breadcrumb = soup.select(\".breadcrumbs\")\n",
    "   \n",
    "    for breadcrumbs in breadcrumb:\n",
    "        cate_list = breadcrumbs.find_all(\"ul\")\n",
    "#         print(\"list: \",cate_list)\n",
    "        for sub_list in cate_list:\n",
    "            c_list = sub_list.text\n",
    "            category.append(c_list.replace('\\n', ''))\n",
    "            print(category)\n",
    "        #                 c = c_list.replace('\\n','')\n",
    "        #                 print(c)\n",
    "\n",
    "    all_sku = soup.select('.product-view')\n",
    "\n",
    "    for sku in all_sku:\n",
    "#             soup = BeautifulSoup(sku.get_attribute('innerHTML'), 'html.parser')\n",
    "            # print(soup.prettify())\n",
    "            # https://www.router-switch.com/juniper-price.html\n",
    "        detail = soup.select('.product-shop')\n",
    "            #             print(detail.prettify())\n",
    "        for sku in detail:\n",
    "            try:\n",
    "                h1 = sku.select('.product-name')\n",
    "                for h in h1:\n",
    "                    pid = h.find('h1').text\n",
    "                    sku = h.find('span', itemprop=\"sku\").text\n",
    "                    brand = h.find('span', itemprop=\"brand\").text\n",
    "                    skus.append(sku)\n",
    "                    brands.append(brand)\n",
    "                    prod_ID.append(pid)\n",
    "            except Exception as e:\n",
    "                h1 = None\n",
    "        for desc in detail:\n",
    "            try:\n",
    "                txt = desc.select(\"table > .data-table,.product-data-table\")\n",
    "                for d in txt:\n",
    "                    descrip = d.find(\"td\", itemprop=\"description\").text\n",
    "                        #                         print(\"Short Description: \",descrip)\n",
    "                sh_descrip.append(descrip)\n",
    "                try:\n",
    "                    op = d.find('td', {'class': 'listprice'}).find('span').text\n",
    "#                             print(\"OLD Prices\",op)\n",
    "                    old_prices.append(op)\n",
    "                except Exception as e:\n",
    "                    op = None\n",
    "                try:\n",
    "                    sp = d.find('td', {'class': 'saleprice'}).find('span', {'class': 'regular-price'}).find(\n",
    "                        'span').text\n",
    "#                             print(\"SALE Prices\\n\",sp)\n",
    "#                             print(\"===============\")\n",
    "                    sale_prices.append(sp)\n",
    "                except Exception as e:\n",
    "                    sp = None\n",
    "            except Exception as e:\n",
    "                desc = None\n",
    "\n",
    "            #                     LONG DESCRIPTION\n",
    "        details = soup.select(\"dd > .tab-container, .dd-specification\")\n",
    "        for long_desc in details:\n",
    "            try:\n",
    "                escp = long_desc.find(\"div\", {'class', 'tab-content'})\n",
    "                    # print(descp)\n",
    "                long_descrip.append(descp)\n",
    "            except Exception as e:\n",
    "                descp = None\n",
    "        #     print(skus) product-img-box\n",
    "    for img in all_sku:\n",
    "        try:\n",
    "            i = img.select('div > .product-image')\n",
    "            for images in i:\n",
    "                link = images.find('a')['href']\n",
    "                print(link)\n",
    "                Images.append(link)\n",
    "        except Exception as e:\n",
    "            i = None\n",
    "#     print(Images)\n",
    "    \n",
    "    data = {'SKUs': skus, 'Category': category, 'Product ID': prod_ID, 'Brand': brands, 'Description': sh_descrip, 'OLD Price': old_prices,\n",
    "            'SALE Price': sale_prices, 'Long descriptions': long_descrip, 'Images': Images, }\n",
    "\n",
    "    df = pd.DataFrame.from_dict(data, orient='index')\n",
    "    df = df.transpose()\n",
    "    print(df)\n",
    "    print(\"Got these many results:\", df.shape)\n",
    "\n",
    "#     file_name = input(\"Name of the file using CSV extention e.g; master files.csv: \")\n",
    "#     df.to_csv(source + \"\" + file_name, index=False)\n",
    "\n",
    "    counter = counter - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def products(urls):\n",
    "    source = \"D://formsProject//scrape//project//static//\"        \n",
    "    skus = []\n",
    "    category = []\n",
    "    brands = []\n",
    "    prod_ID = []\n",
    "    sh_descrip = []\n",
    "    long_descrip = []\n",
    "    old_prices = []\n",
    "    sale_prices = []\n",
    "    Images = []\n",
    "\n",
    "    headers = requests.utils.default_headers()\n",
    "    headers.update({ \"User-Agent\":\"Mozilla/5.0 (Macintosh; Intel Mac OSX 10_14_3) AppleWebKit/537.36 (KHTML, like Gecko)Chrome/71.0.3578.98 Safari/537.36\", \"Accept\":\"text/html,application/xhtml+xml,application/xml; q=0.9,image/webp,image/apng,*/*;q=0.8\"})\n",
    "    fp = open(urls, 'r', encoding='utf-8')\n",
    "    url = fp.readlines()\n",
    "    for links in url:\n",
    "        page = requests.get(links, headers=headers)\n",
    "        time.sleep(90)\n",
    "        print(\"Page Connection code: \", page.status_code)\n",
    "        print(links)\n",
    "        if page.status_code == 503:\n",
    "            print(\"Page Connection code: \", page.status_code)\n",
    "            return products(urls)\n",
    "        soup = BeautifulSoup(page.text, 'lxml')\n",
    "\n",
    "        breadcrumb = soup.select(\".breadcrumbs\")\n",
    "        print(breadcrumb)\n",
    "        \n",
    "        for breadcrumbs in breadcrumb:\n",
    "            cate_list = breadcrumbs.find_all(\"ul\")\n",
    "            for sub_list in cate_list:\n",
    "                c_list = sub_list.text\n",
    "                category = [c_list.replace('\\n','')]\n",
    "\n",
    "        all_sku = soup.select('.product-view')\n",
    "        for sku in all_sku:\n",
    "            detail = soup.select('.product-shop')\n",
    "            for sku in detail:\n",
    "                try:\n",
    "                    h1 = sku.select('.product-name')\n",
    "                    for h in h1:\n",
    "                        pid = h.find('h1').text\n",
    "                        sku = h.find('span', itemprop=\"sku\").text\n",
    "                        brand = h.find('span', itemprop=\"brand\").text\n",
    "                        skus = [sku]\n",
    "                        brands = [brand]\n",
    "                        prod_ID = [pid]\n",
    "                except Exception as e:\n",
    "                    h1 = None\n",
    "            for desc in detail:\n",
    "                try:\n",
    "                    txt = desc.select(\"table > .data-table,.product-data-table\")\n",
    "                    for d in txt:\n",
    "                        descrip = d.find(\"td\", itemprop=\"description\").text\n",
    "                        sh_descrip = [descrip]\n",
    "                        try:\n",
    "                                op = d.find('td', {'class': 'listprice'}).find('span').text\n",
    "                                old_prices = [op]\n",
    "\n",
    "                        except Exception as e:\n",
    "                            op = None\n",
    "                        try:\n",
    "                            sp = d.find('td', {'class': 'saleprice'}).find('span', {'class': 'regular-price'}).find('span').text\n",
    "                            sale_prices = [sp]\n",
    "                        except Exception as e:\n",
    "                            sp = None   \n",
    "                except Exception as e:\n",
    "                    desc = None\n",
    "\n",
    "                #LONG DESCRIPTION\n",
    "            details = soup.select(\"dd > .tab-container, .dd-specification\")\n",
    "            for long_desc in details:\n",
    "                try:\n",
    "                    descp = long_desc.find(\"div\", {'class', 'tab-content'})\n",
    "                    long_descrip = [descp]\n",
    "                except Exception as e:\n",
    "                    descp = None\n",
    "\n",
    "        for img in all_sku:\n",
    "            try:\n",
    "                i = img.select('div > .product-image')\n",
    "                for images in i:\n",
    "                    link = images.find('a')['href']\n",
    "        #                 print(link)\n",
    "                    Images.append(link)\n",
    "            except Exception as e:\n",
    "                i = None\n",
    "\n",
    "    data = {'SKUs': skus, 'Category': category, 'Product ID': prod_ID, 'Brand': brands, 'Description': sh_descrip, 'OLD Price': old_prices,\n",
    "                        'SALE Price': sale_prices, 'Long descriptions': long_descrip, 'Images': Images, }\n",
    "\n",
    "\n",
    "    df = pd.DataFrame.from_dict(data, orient='index')\n",
    "    df = df.transpose()\n",
    "    print(df)\n",
    "    print(\"Got these many results:\", df.shape)\n",
    "\n",
    "#         file_name = input(\"Name of the file using CSV extention e.g; master files.csv: \")\n",
    "#         df.to_csv(source + \"\" + file_name, index=False)\n",
    "\n",
    "#         counter = counter - 1\n",
    "\n",
    "    return df\n",
    "\n",
    "# print(get_file_links('https://www.router-switch.com/air-band-inst-tl-p-5685.html'))\n",
    "# path = 'D://formsProject//scrape//project//static//Cisco ASA 5500 Series.txt'\n",
    "\n",
    "products('D://ormusa//cisco-routers//Ciscowireless links.txt')\n",
    "\n",
    "# read_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url= 'https://www.router-switch.com/asa5512-k9-p-4613.html'\n",
    "# Set headers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DAY USER\\AppData\\Local\\Temp\\ipykernel_8476\\2256251705.py:23: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(chrome_options=option, executable_path=\"./chromedriver\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SKUs': [], 'Category': ['                                    Home                                                                    Optical Access Network                                                                    Huawei Access Network                                                                    Huawei OLT                                                                    Huawei SmartAX EA5800 Series OLT                                EA5800-X17', '                                    Home                                                                    Optical Access Network                                                                    Huawei Access Network                                                                    Huawei OLT                                                                    Huawei SmartAX EA5800 Series OLT                                EA5800-X15', '                                    Home                                                                    Optical Access Network                                                                    Huawei Access Network                                                                    Huawei OLT                                                                    Huawei SmartAX EA5800 Series OLT                                EA5800-X7', '                                    Home                                                                    Optical Access Network                                                                    Huawei Access Network                                                                    Huawei OLT                                                                    Huawei SmartAX EA5800 Series OLT                                EA5800-X2'], 'Product ID': [], 'Brand': [], 'Description': [], 'OLD Price': [], 'SALE Price': [], 'Long descriptions': [], 'Images': []}\n",
      "   SKUs                                           Category Product ID Brand  \\\n",
      "0  None                                      Home      ...       None  None   \n",
      "1  None                                      Home      ...       None  None   \n",
      "2  None                                      Home      ...       None  None   \n",
      "3  None                                      Home      ...       None  None   \n",
      "\n",
      "  Description OLD Price SALE Price Long descriptions Images  \n",
      "0        None      None       None              None   None  \n",
      "1        None      None       None              None   None  \n",
      "2        None      None       None              None   None  \n",
      "3        None      None       None              None   None  \n",
      "Got these many results: (4, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SKUs</th>\n",
       "      <th>Category</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>OLD Price</th>\n",
       "      <th>SALE Price</th>\n",
       "      <th>Long descriptions</th>\n",
       "      <th>Images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>Home      ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>Home      ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>Home      ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>Home      ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SKUs                                           Category Product ID Brand  \\\n",
       "0  None                                      Home      ...       None  None   \n",
       "1  None                                      Home      ...       None  None   \n",
       "2  None                                      Home      ...       None  None   \n",
       "3  None                                      Home      ...       None  None   \n",
       "\n",
       "  Description OLD Price SALE Price Long descriptions Images  \n",
       "0        None      None       None              None   None  \n",
       "1        None      None       None              None   None  \n",
       "2        None      None       None              None   None  \n",
       "3        None      None       None              None   None  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def products(urls):\n",
    "    source = \"C://Users//DAY USER//Documents//Scapper//\"        \n",
    "    skus = []\n",
    "    category = []\n",
    "    brands = []\n",
    "    prod_ID = []\n",
    "    sh_descrip = []\n",
    "    long_descrip = []\n",
    "    old_prices = []\n",
    "    sale_prices = []\n",
    "    Images = []\n",
    "\n",
    "    option = Options()\n",
    "    option.add_argument(\"--disable-infobars\")\n",
    "    option.add_argument(\"start-maximized\")\n",
    "    option.add_argument(\"--disable-extensions\")\n",
    "\n",
    "    # Pass the argument 1 to allow and 2 to block\n",
    "    option.add_experimental_option(\"prefs\", {\n",
    "        \"profile.default_content_setting_values.notifications\": 1\n",
    "    })\n",
    "#     option.headless = True\n",
    "    driver = webdriver.Chrome(chrome_options=option, executable_path=\"./chromedriver\")\n",
    "    \n",
    "    fp = open(urls,'r', encoding='utf-8')\n",
    "    url = fp.readlines()\n",
    "    for links in url:\n",
    "        driver.get(links)\n",
    "        driver.implicitly_wait(60)\n",
    "\n",
    "        breadcrumb = driver.find_elements_by_class_name('main')\n",
    "        \n",
    "        for breadcrumbs in breadcrumb:\n",
    "            soup = BeautifulSoup(breadcrumbs.get_attribute('innerHTML'), 'html.parser')\n",
    "            cate_list = soup.select('.breadcrumbs')\n",
    "            for sub_list in cate_list:\n",
    "                c_list = sub_list.text\n",
    "                category.append(c_list.replace('\\n', ''))\n",
    "        \n",
    "\n",
    "        all_sku = driver.find_elements_by_class_name('product-view')\n",
    "\n",
    "        for sku in all_sku:\n",
    "            soup = BeautifulSoup(sku.get_attribute('innerHTML'), 'html.parser')\n",
    "            # print(soup.prettify())\n",
    "            # https://www.router-switch.com/juniper-price.html\n",
    "            detail = soup.select('.product-shop')\n",
    "            #             print(detail.prettify())\n",
    "            for sku in detail:\n",
    "                try:\n",
    "                    h1 = sku.select('.product-name')\n",
    "                    for h in h1:\n",
    "                        pid = h.find('h1').text\n",
    "                        sku = h.find('span', itemprop=\"sku\").text\n",
    "                        brand = h.find('span', itemprop=\"brand\").text\n",
    "                        skus.append(sku)\n",
    "                        brands.append(brand)\n",
    "                        prod_ID.append(pid)\n",
    "                except Exception as e:\n",
    "                    h1 = None\n",
    "            for desc in detail:\n",
    "                try:\n",
    "                    txt = desc.select(\"table > .data-table,.product-data-table\")\n",
    "                    for d in txt:\n",
    "                        descrip = d.find(\"td\", itemprop=\"description\").text\n",
    "                        #                         print(\"Short Description: \",descrip)\n",
    "                        sh_descrip.append(descrip)\n",
    "                        try:\n",
    "                            op = d.find('td', {'class': 'listprice'}).find('span').text\n",
    "#                             print(\"OLD Prices\",op)\n",
    "                            old_prices.append(op)\n",
    "                        except Exception as e:\n",
    "                            op = None\n",
    "                        try:\n",
    "                            sp = d.find('td', {'class': 'saleprice'}).find('span', {'class': 'regular-price'}).find(\n",
    "                                'span').text\n",
    "#                             print(\"SALE Prices\\n\",sp)\n",
    "#                             print(\"===============\")\n",
    "                            sale_prices.append(sp)\n",
    "                        except Exception as e:\n",
    "                            sp = None\n",
    "                except Exception as e:\n",
    "                    desc = None\n",
    "\n",
    "            #                     LONG DESCRIPTION\n",
    "            details = soup.select(\"dd > .tab-container, .dd-specification\")\n",
    "            for long_desc in details:\n",
    "                try:\n",
    "                    descp = long_desc.find(\"div\", {'class', 'tab-content'})\n",
    "                    # print(descp)\n",
    "                    long_descrip.append(descp)\n",
    "                except Exception as e:\n",
    "                    descp = None\n",
    "        #     print(skus) product-img-box\n",
    "        for img in all_sku:\n",
    "            soup = BeautifulSoup(img.get_attribute('innerHTML'), 'html.parser')\n",
    "            #             print(soup.prettify())\n",
    "            try:\n",
    "                i = soup.select('div > .product-image')\n",
    "                for images in i:\n",
    "                    link = images.find('a')['href']\n",
    "                    print(link)\n",
    "                    Images.append(link)\n",
    "            except Exception as e:\n",
    "                i = None\n",
    "                \n",
    "    data = {'SKUs': skus, 'Category': category, 'Product ID': prod_ID, 'Brand': brands, 'Description': sh_descrip, 'OLD Price': old_prices,\n",
    "                        'SALE Price': sale_prices, 'Long descriptions': long_descrip, 'Images': Images, }\n",
    "    print(data)\n",
    "\n",
    "    df = pd.DataFrame.from_dict(data, orient='index')\n",
    "    df = df.transpose()\n",
    "    print(df)\n",
    "    print(\"Got these many results:\", df.shape)\n",
    "\n",
    "#     file_name = input(\"Name of the file using CSV extention e.g; master files.csv: \")\n",
    "#     df.to_csv(source + \"\" + file_name, index=False)\n",
    "\n",
    "#         counter = counter - 1\n",
    "\n",
    "    return df\n",
    "\n",
    "# print(get_file_links('https://www.router-switch.com/air-band-inst-tl-p-5685.html'))\n",
    "# path = 'D://formsProject//scrape//project//static//Cisco ASA 5500 Series.txt'\n",
    "\n",
    "products('C://Users//DAY USER//Documents//Scapper//Huawei.txt')\n",
    "\n",
    "# read_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "list_of_files = glob.glob('/path/to/folder/*') # * means all if need specific format then *.csv\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "print(latest_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flask scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries and files\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "from os import path\n",
    "\n",
    "def products(urls):\n",
    "#         url= 'https://www.router-switch.com/asa5512-k9-p-4613.html'\n",
    "    # Set headers\n",
    "    skus = []\n",
    "    category = []\n",
    "    brands = []\n",
    "    prod_ID = []\n",
    "    sh_descrip = []\n",
    "    long_descrip = []\n",
    "    old_prices = []\n",
    "    sale_prices = []\n",
    "    Images = []\n",
    "    counter = int(input('Make a threads of bot more than 1:'))\n",
    "    while counter >= 1:\n",
    "        option = Options()\n",
    "        option.add_argument(\"--disable-infobars\")\n",
    "        option.add_argument(\"start-maximized\")\n",
    "        option.add_argument(\"--disable-extensions\")\n",
    "\n",
    "        # Pass the argument 1 to allow and 2 to block\n",
    "        option.add_experimental_option(\"prefs\", {\n",
    "            \"profile.default_content_setting_values.notifications\": 1\n",
    "        })\n",
    "        option.headless = True\n",
    "        driver = webdriver.Chrome(chrome_options=option, executable_path=\"C://Users//USER//Netflix Recommendation engine//chromedriver\")\n",
    "        \n",
    "        fp = open(urls,'r', encoding='utf-8')\n",
    "        url = fp.readlines()\n",
    "        for links in url:\n",
    "            driver.get(links)\n",
    "            driver.implicitly_wait(60)\n",
    "\n",
    "            breadcrumb = driver.find_elements_by_class_name('main')\n",
    "            \n",
    "            for breadcrumbs in breadcrumb:\n",
    "                soup = BeautifulSoup(breadcrumbs.get_attribute('innerHTML'), 'html.parser')\n",
    "                cate_list = soup.select('.breadcrumbs')\n",
    "                for sub_list in cate_list:\n",
    "                    c_list = sub_list.text\n",
    "                    category.append(c_list.replace('\\n', ''))\n",
    "            \n",
    "\n",
    "            all_sku = driver.find_elements_by_class_name('product-view')\n",
    "\n",
    "            for sku in all_sku:\n",
    "                soup = BeautifulSoup(sku.get_attribute('innerHTML'), 'html.parser')\n",
    "\n",
    "                detail = soup.select('.product-shop')\n",
    "                for sku in detail:\n",
    "                    try:\n",
    "                        h1 = sku.select('.product-name')\n",
    "\n",
    "                        for h in h1:\n",
    "                            try:\n",
    "                                pid = h.find('h1', itemprop=\"name\").text\n",
    "                                prod_ID.append(pid)\n",
    "\n",
    "                            except Exception as e:\n",
    "                                pid = None\n",
    "                            try:\n",
    "                                sku = h.find('span', itemprop=\"sku\").text\n",
    "                                skus.append(sku)\n",
    "\n",
    "                            except Exception as e:\n",
    "                                sku = None\n",
    "                            try:\n",
    "\n",
    "                                brand = h.find('span', itemprop=\"brand\").text\n",
    "                                brands.append(brand)\n",
    "                            except Exception as e:\n",
    "                                brand = None\n",
    "\n",
    "                            # print( skus + brands + prod_ID)\n",
    "                    except Exception as e:\n",
    "                        h1 = None\n",
    "                for desc in detail:\n",
    "                    try:\n",
    "                        txt = desc.select(\"table > .data-table,.product-data-table\")\n",
    "                        for d in txt:\n",
    "                            descrip = d.find(\"td\", itemprop=\"description\").text\n",
    "                            #                         print(\"Short Description: \",descrip)\n",
    "                            sh_descrip.append(descrip)\n",
    "                            try:\n",
    "                                op = d.find('td', {'class': 'listprice'}).find('span').text\n",
    "    #                             print(\"OLD Prices\",op)\n",
    "                                old_prices.append(op)\n",
    "                            except Exception as e:\n",
    "                                op = None\n",
    "                            try:\n",
    "                                sp = d.find('td', {'class': 'saleprice'}).find('span', {'class': 'regular-price'}).find(\n",
    "                                    'span').text\n",
    "    #                             print(\"SALE Prices\\n\",sp)\n",
    "    #                             print(\"===============\")\n",
    "                                sale_prices.append(sp)\n",
    "                            except Exception as e:\n",
    "                                sp = None\n",
    "                    except Exception as e:\n",
    "                        desc = None\n",
    "\n",
    "                #                     LONG DESCRIPTION\n",
    "                details = soup.select(\"dd > .tab-container, .dd-specification\")\n",
    "                for long_desc in details:\n",
    "                    try:\n",
    "                        descp = long_desc.find(\"div\", {'class', 'tab-content'})\n",
    "                        # print(descp)\n",
    "                        long_descrip.append(descp)\n",
    "                    except Exception as e:\n",
    "                        descp = None\n",
    "            #     print(skus) product-img-box\n",
    "            for img in all_sku:\n",
    "                soup = BeautifulSoup(img.get_attribute('innerHTML'), 'html.parser')\n",
    "                #             print(soup.prettify())\n",
    "                try:\n",
    "                    i = soup.select('div > .product-image')\n",
    "                    for images in i:\n",
    "                        link = images.find('a')['href']\n",
    "                        # print(link)\n",
    "                        Images.append(link)\n",
    "                except Exception as e:\n",
    "                    i = None\n",
    "    \n",
    "\n",
    "        \n",
    "        data = {'SKUs': skus, 'Category': category, 'Product ID': prod_ID, 'Brand': brands, 'Description': sh_descrip, 'OLD Price': old_prices,\n",
    "                'SALE Price': sale_prices, 'Long descriptions': long_descrip, 'Images': Images, }\n",
    "        counter = counter - 1\n",
    "        return data\n",
    "\n",
    "def product_files(data):\n",
    "    # source = \"D://formsProject//scrape//project//static//\"\n",
    "    df = pd.DataFrame.from_dict(products(data), orient='index')\n",
    "    df = df.transpose()\n",
    "    print(df)\n",
    "    print(\"Got these many results:\", df.shape)\n",
    "\n",
    "    # file_name = input(\"Name of the file using CSV extention e.g; master files.csv: \")\n",
    "    # df.to_csv(source + \"\" + file_name, index=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     scraper = product_files()\n",
    "#     scraper.run\n",
    "# print(get_file_links('https://www.router-switch.com/air-band-inst-tl-p-5685.html'))\n",
    "# product_files('https://www.router-switch.com/air-band-inst-tl-p-5685.html')\n",
    "# links = ['https://www.router-switch.com/air-band-inst-tl-p-5685.html','https://www.router-switch.com/asa5512-k9-p-4613.html']\n",
    "# product_files('D://ormusa//cisco-routers//links.txt')\n",
    "# product_files(links)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
