{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70ea26fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import re\n",
    "from datetime import datetime\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b55b0c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the headers\n",
    "headers = requests.utils.default_headers()\n",
    "\n",
    "headers.update(\n",
    "    {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8b3e954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list variables\n",
    "\n",
    "title = []\n",
    "images = []\n",
    "titleLabels = []\n",
    "descriptionTitle = []\n",
    "stockSpecificInformation = []\n",
    "stockOptions = []\n",
    "options_key_values = []\n",
    "options_value_values = []\n",
    "stockDescription3 = []\n",
    "stockDescription4 = []\n",
    "optionDetails = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96566167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "response = requests.get('https://www.nikkyocars.com/m/?lang=en', headers=headers)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8ee9dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "urls = [\"https://www.tc-v.com/used_car/bmw/1%20series/33693276/?isNew=1\"]\n",
    "for i in range(0, len(urls)):\n",
    "    page = requests.get(urls[i], headers=headers)\n",
    "    print(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ec39600",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "# print(soup.prettify())\n",
    "# alldiv = soup.find_All('article',class_='car__detail-wrap')\n",
    "# left side data\n",
    "getMainDiv = soup.find(\"div\",class_=\"car__detail-main-area\")\n",
    "# Images\n",
    "for getImages in getMainDiv:\n",
    "    getImage = getImages.find_all(\"img\", src=True)\n",
    "    for image in getImage:\n",
    "        images.append(image[\"src\"])\n",
    "#print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd5d79c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description data variable\n",
    "getDescriptionsTitle = getMainDiv.find_all('h2',class_=\"car__info-ttl\")\n",
    "for titles in getDescriptionsTitle:\n",
    "    titleLabels.append(titles.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3af932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Car Specific information\n",
    "for section in getMainDiv:\n",
    "    # description\n",
    "    getDescriptions = section.find(\"table\")\n",
    "    \n",
    "stockSpecificInformation.append(getDescriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f08c2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for section in getMainDiv:\n",
    "    # details description\n",
    "    getDescriptionsDl = section.select(\"dl\")\n",
    "    for detail in getDescriptionsDl:\n",
    "        dtKeys = detail.find_all(\"dt\")\n",
    "        ddValues = detail.find_all(\"dd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba8757cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure both lists have the same length using zip\n",
    "key_value_pairs = zip(dtKeys * len(ddValues), ddValues)\n",
    "\n",
    "# Create a DataFrame from the key-value pairs\n",
    "df = pd.DataFrame(key_value_pairs, columns=[\"dtKey\", \"ddValue\"])\n",
    "\n",
    "# Iterate over the rows of the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    key_val = row[\"dtKey\"]\n",
    "    value_val = row[\"ddValue\"]\n",
    "    # print(key_val, value_val)\n",
    "\n",
    "    options_key_values.append(key_val)\n",
    "    options_value_values.append(value_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d748085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape car title\n",
    "car_title = soup.find(\"h1\", class_=\"car__detail-ttl\").text.strip()\n",
    "\n",
    "# Scrape car price\n",
    "car_price = soup.find(\"div\", class_=\"car__price-body\").text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9388b918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape car specifications\n",
    "specifications = soup.find_all(\"section\", class_=\"car_info-area\")\n",
    "\n",
    "# Create a dictionary to store car specifications\n",
    "car_specifications = {}\n",
    "\n",
    "for spec in specifications:\n",
    "    label = spec.find(\"th\", class_=\"car__info-table-ttl\")\n",
    "    value = spec.find(\"td\", class_=\"car__info-table-body\")\n",
    "    car_specifications[label] = value\n",
    "\n",
    "# Scrape car options\n",
    "options = soup.find_all(\"section\", class_=\"car_info-area\")\n",
    "\n",
    "# Create a list to store car options\n",
    "car_options = []\n",
    "\n",
    "for option in options:\n",
    "    option_name = option.find(\"dt\", class_=\"option__item-ttl\")\n",
    "    option_value = option.find(\"dd\", class_=\"option__item\")\n",
    "    car_options.append(f\"{option_name}: {option_value}\")\n",
    "\n",
    "# Create separate lists for each key in the data dictionary\n",
    "car_titles = [car_title]\n",
    "car_prices = [car_price]\n",
    "car_option_lists = [\" | \".join(car_options)]\n",
    "\n",
    "# Repeat the specifications for each car title\n",
    "car_specification_lists = {\n",
    "    label: [value] * len(car_titles) for label, value in car_specifications.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c036e8e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create a DataFrame from the scraped data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCar Title\u001b[39m\u001b[38;5;124m\"\u001b[39m: car_titles,\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCar Price\u001b[39m\u001b[38;5;124m\"\u001b[39m: car_prices,\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImages\u001b[39m\u001b[38;5;124m\"\u001b[39m: images,\n\u001b[0;32m      6\u001b[0m     titleLabels[\u001b[38;5;241m0\u001b[39m]: stockSpecificInformation,\n\u001b[0;32m      7\u001b[0m     titleLabels[\u001b[38;5;241m1\u001b[39m]: car_option_lists,\n\u001b[0;32m      8\u001b[0m     options_key_values: options_value_values,\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcar_specification_lists,\n\u001b[0;32m     10\u001b[0m }\n\u001b[0;32m     12\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Save the DataFrame to a CSV file\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame from the scraped data\n",
    "data = {\n",
    "    \"Car Title\": car_titles,\n",
    "    \"Car Price\": car_prices,\n",
    "    \"Images\": images,\n",
    "    titleLabels[0]: stockSpecificInformation,\n",
    "    titleLabels[1]: car_option_lists,\n",
    "    options_key_values: options_value_values,\n",
    "    **car_specification_lists,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"car_data.csv\", index=False)\n",
    "\n",
    "print(\"Data has been scraped and saved to car_data.csv.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686c5fca",
   "metadata": {},
   "source": [
    "## TC-V Scrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f54ee07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated \n",
      "Estimated \n",
      "Estimated \n",
      "Estimated \n",
      "Estimated \n",
      "Estimated \n",
      "                        Car Title  Car Price Car Total Price  \\\n",
      "0               2007 BMW 1 Series   US$2,863                   \n",
      "1  2007 Toyota Land Cruiser Prado  US$10,963                   \n",
      "2  2007 Toyota Land Cruiser Prado  US$10,726                   \n",
      "3                2008 Mazda Demio   US$4,031                   \n",
      "4                     2013 BMW X1   US$6,950                   \n",
      "5                1996 Suzuki Alto   US$1,994                   \n",
      "\n",
      "                                          Car Images  \\\n",
      "0  https://www.tc-v.com/cdn/trade/img06/cars/3147...   \n",
      "1  https://www.tc-v.com/cdn/trade/img06/cars/3147...   \n",
      "2  https://www.tc-v.com/cdn/trade/img06/cars/3147...   \n",
      "3  https://www.tc-v.com/cdn/trade/img06/cars/3147...   \n",
      "4  https://www.tc-v.com/cdn/trade/img06/cars/3147...   \n",
      "5  https://www.tc-v.com/cdn/trade/img06/cars/3147...   \n",
      "\n",
      "                                        Car Features  \\\n",
      "0  64,084 km | Automatic | - | Gasoline/Petrol | ...   \n",
      "1  64,084 km | Automatic | - | Gasoline/Petrol | ...   \n",
      "2  64,084 km | Automatic | - | Gasoline/Petrol | ...   \n",
      "3  64,084 km | Automatic | - | Gasoline/Petrol | ...   \n",
      "4  64,084 km | Automatic | - | Gasoline/Petrol | ...   \n",
      "5  64,084 km | Automatic | - | Gasoline/Petrol | ...   \n",
      "\n",
      "       VIN(Vehicle Identification Number)/Serial No.  \\\n",
      "0  [WBAUE12090PC76***Full VIN/Serial No. will be ...   \n",
      "1  [TRJ120-5078***Full VIN/Serial No. will be sho...   \n",
      "2  [TRJ120-5068***Full VIN/Serial No. will be sho...   \n",
      "3  [DE3FS-145***Full VIN/Serial No. will be shown...   \n",
      "4  [WBAVL92070VU22***Full VIN/Serial No. will be ...   \n",
      "5  [---***Full VIN/Serial No. will be shown on Pr...   \n",
      "\n",
      "                              Model Code Registration Year / Month  \\\n",
      "0                                    [-]                    [2007]   \n",
      "1                          [CBA-TRJ120W]                    [2007]   \n",
      "2                          [CBA-TRJ120W]                    [2007]   \n",
      "3                                [DE3FS]                 [2008/04]   \n",
      "4  [BMW X1 SDRIVE20I AT D/AB HID SR NAV]                 [2013/02]   \n",
      "5                                    [-]                    [1996]   \n",
      "\n",
      "    Manufacture Year / Month       Mileage  ...      Drive Type Door  \\\n",
      "0  [Confirm with the Seller]   [64,084 km]  ...             [-]  [5]   \n",
      "1                     [2007]   [72,378 km]  ...  [4wheel drive]  [5]   \n",
      "2                     [2007]  [102,656 km]  ...  [4wheel drive]  [5]   \n",
      "3  [Confirm with the Seller]    [5,000 km]  ...  [2wheel drive]  [5]   \n",
      "4                     [2012]   [64,425 km]  ...  [2wheel drive]  [5]   \n",
      "5  [Confirm with the Seller]   [26,000 km]  ...             [-]  [3]   \n",
      "\n",
      "  Number of Seats                    Dimension             Condition  \\\n",
      "0             [5]                          [-]                [Used]   \n",
      "1             [5]  [472cm×188cm×191cm=16.95m³]                [Used]   \n",
      "2             [8]  [472cm×188cm×191cm=16.95m³]                [Used]   \n",
      "3             [5]   [390cm×170cm×148cm=9.81m³]                [Used]   \n",
      "4             [5]  [445cm×204cm×154cm=13.98m³]  [Used (No Accident)]   \n",
      "5             [4]                          [-]                [Used]   \n",
      "\n",
      "                               ID Remarks (Any Problems)  \\\n",
      "0   [3147874-KRM12790-12793-289R]                    [-]   \n",
      "1          [3124746-220621200516]                    [-]   \n",
      "2          [3124746-230209102148]                    [-]   \n",
      "3  [3250454-3255531-230214145800]                    [-]   \n",
      "4  [3173992-3226545-230224164115]                    [-]   \n",
      "5    [3147874-KRM26508-26516-25R]                    [-]   \n",
      "\n",
      "                                             Comment              Expiry Date  \\\n",
      "0                                                [-]  [Aug / 27 / 2023 (JST)]   \n",
      "1                                                [-]  [Jun / 02 / 2023 (JST)]   \n",
      "2  [Looks & runs great\\nVery clean interior\\nRuns...  [Jun / 14 / 2023 (JST)]   \n",
      "3                                                [-]  [Jun / 23 / 2023 (JST)]   \n",
      "4  [Must see\\nVery clean interior\\nLooks & runs g...  [Jun / 14 / 2023 (JST)]   \n",
      "5                                                [-]  [Aug / 23 / 2023 (JST)]   \n",
      "\n",
      "                                         Car Options  \n",
      "0  Driver Airbag | Anti-Lock Brakes | Passenger A...  \n",
      "1  Driver Airbag | Anti-Lock Brakes | Passenger A...  \n",
      "2  Driver Airbag | Anti-Lock Brakes | Passenger A...  \n",
      "3  Driver Airbag | Anti-Lock Brakes | Passenger A...  \n",
      "4  Driver Airbag | Anti-Lock Brakes | Passenger A...  \n",
      "5  Driver Airbag | Anti-Lock Brakes | Passenger A...  \n",
      "\n",
      "[6 rows x 28 columns]\n",
      "Got these many results: (6, 28)\n",
      "Data has been scraped and saved to CSV file\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Define the headers\n",
    "headers = requests.utils.default_headers()\n",
    "\n",
    "headers.update(\n",
    "    {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# List of URLs to scrape\n",
    "urls = [\n",
    "    \"https://www.tc-v.com/used_car/bmw/1%20series/33693276/?isNew=1\",\n",
    "    \"https://www.tc-v.com/used_car/toyota/land%20cruiser%20prado/32929679/?isNew=1\",\n",
    "    \"https://www.tc-v.com/used_car/toyota/land%20cruiser%20prado/32668631/?isNew=1\",\n",
    "    \"https://www.tc-v.com/used_car/mazda/demio/32738225/?isNew=1\",\n",
    "    \"https://www.tc-v.com/used_car/bmw/x1/33633147/?isNew=1\",\n",
    "    \"https://www.tc-v.com/used_car/suzuki/alto/32236783/?isNew=1\",\n",
    "]\n",
    "\n",
    "# Create an empty list to store the scraped data\n",
    "all_data = []\n",
    "images = []\n",
    "stock_specific_information = []\n",
    "title_labels = []\n",
    "title_values = []\n",
    "options_key_values = []\n",
    "options_value_values = []\n",
    "features_info = []\n",
    "car_names = []\n",
    "car_fob_price = []\n",
    "car_estimated_price = []\n",
    "\n",
    "# Iterate over each URL\n",
    "for url in urls:\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url, headers=headers, timeout=5)\n",
    "\n",
    "    # Create a BeautifulSoup object to parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Scrape car title\n",
    "    car_title = soup.find(\"h1\", class_=\"car__detail-ttl\").text.strip()\n",
    "    car_names.append(car_title)\n",
    "    \n",
    "    # Scrape features under title\n",
    "    cars_feature = soup.select(\".car__detail-tag-item\")\n",
    "    for features in cars_feature:\n",
    "        feature = features.text.strip()\n",
    "        features_info.append(feature)\n",
    "\n",
    "    # Scrape car price\n",
    "    car_price = soup.find(\"div\", class_=\"car__price-body\").text.strip()\n",
    "    car_fob_price.append(car_price)\n",
    "    \n",
    "     # Scrape car estimate total pricing\n",
    "    # car_price_estimated = soup.find(\n",
    "    #     \"span\", attrs={\"data-car-target\": \"displayTotalPriceEl\"}\n",
    "    # )\n",
    "    car_total_price = soup.find(\n",
    "        \"span\", attrs={\"data-car-target\": \"displayTotalPriceEl\"}\n",
    "    ).text.strip()\n",
    "\n",
    "    print(\"Estimated\", car_total_price)\n",
    "    car_estimated_price.append(car_total_price)\n",
    "    \n",
    "    # Scrape car images\n",
    "    \n",
    "    image_elements = soup.find_all(\"div\", class_=\"car__detail-main-area\")\n",
    "\n",
    "    for getImages in image_elements:\n",
    "        getImage = getImages.find_all(\"img\", src=True)\n",
    "        for imageUrl in getImage:\n",
    "            images.append(imageUrl[\"src\"])\n",
    "\n",
    "    # Scrape stock-specific information\n",
    "    info_elements = soup.find_all(\"li\", class_=\"detail__list-item\")\n",
    "    for info_element in info_elements:\n",
    "        info_text = info_element.text.strip()\n",
    "        stock_specific_information.append(info_text)\n",
    "\n",
    "    # Scrape title labels and values\n",
    "    title_elements = soup.find_all(\"th\", class_=\"car__info-table-ttl\")\n",
    "    for title_element in title_elements:\n",
    "        title_text = title_element.text.strip()\n",
    "        title_labels.append(title_text)\n",
    "\n",
    "        \n",
    "    value_elements = soup.find_all(\"td\", class_=\"car__info-table-body\")\n",
    "    for value_element in value_elements:\n",
    "        value_text = value_element.text.strip()\n",
    "        title_values.append(value_text)\n",
    "\n",
    "    # Scrape car options\n",
    "    options_elements = soup.find_all(\"dt\", class_=\"option__item-ttl\")\n",
    "    for option_element in options_elements:\n",
    "        option_text = option_element.text.strip()\n",
    "        options_key_values.append(option_text)\n",
    "\n",
    "    values_elements = soup.find_all(\"dd\", class_=\"option__item\")\n",
    "    for value_element in values_elements:\n",
    "        value_text = value_element.text.strip()\n",
    "        options_value_values.append(value_text)\n",
    "\n",
    "    # Remove square brackets and single quotes from the scraped data\n",
    "    car_title = re.sub(r\"[\\[\\]']\", \"\", car_title)\n",
    "    car_price = re.sub(r\"[\\[\\]']\", \"\", car_price)\n",
    "    images = [re.sub(r\"[\\[\\]']\", \"\", image) for image in images]\n",
    "    stock_specific_information = [re.sub(r\"[\\[\\]']\", \"\", info) for info in stock_specific_information]\n",
    "    title_labels = [re.sub(r\"[\\[\\]']\", \"\", label) for label in title_labels]\n",
    "    title_values = [re.sub(r\"[\\[\\]']\", \"\", value) for value in title_values]\n",
    "    options_key_values = [re.sub(r\"[\\[\\]']\", \"\", option) for option in options_key_values]\n",
    "    options_value_values = [re.sub(r\"[\\[\\]']\", \"\", option) for option in options_value_values]\n",
    "\n",
    "    # Create separate lists for each key in the data dictionary\n",
    "    car_titles = [car_title]\n",
    "    car_prices = [car_price]\n",
    "    car_images = [\" | \".join(images)]\n",
    "    stock_specific_info_lists = {label: [value] * len(car_titles) for label, value in zip(title_labels, title_values)}\n",
    "    car_option_lists = [\" | \".join(options_value_values)]\n",
    "\n",
    "    # Create a dictionary for the scraped data from the current URL\n",
    "    data = {\n",
    "        \"Car Title\": car_title,\n",
    "        \"Car Price\": car_price,\n",
    "        \"Car Total Price\": car_total_price,\n",
    "        \"Car Images\": \" | \".join(images),\n",
    "        \"Car Features\": \" | \".join(features_info),\n",
    "        **stock_specific_info_lists,\n",
    "        \"Car Options\": \" | \".join(options_value_values),\n",
    "    }\n",
    "\n",
    "    # Append the data to the list of all data\n",
    "    all_data.append(data)\n",
    "\n",
    "    # Add a 1-minute delay between each URL scrape\n",
    "    time.sleep(5)\n",
    "\n",
    "# Create a DataFrame from the list of all data\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "print(df)\n",
    "print(\"Got these many results:\", df.shape)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "currentDateTime = datetime.now().strftime(\"%m-%d-%Y-%H-%M-%S-%p\")\n",
    "df.to_csv(f\"tc-v-{currentDateTime}.csv\", index=False)\n",
    "print(\"Data has been scraped and saved to CSV file\")\n",
    "\n",
    "# Add a delay\n",
    "time.sleep(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4c5d801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated \n",
      "Estimated \n",
      "Estimated \n",
      "Estimated \n",
      "Estimated \n",
      "Estimated \n",
      "                        Car Title  Car Price Car Total Price  \\\n",
      "0               2007 BMW 1 Series   US$2,863                   \n",
      "1  2007 Toyota Land Cruiser Prado  US$10,963                   \n",
      "2  2007 Toyota Land Cruiser Prado  US$10,726                   \n",
      "3                2008 Mazda Demio   US$4,031                   \n",
      "4                     2013 BMW X1   US$6,950                   \n",
      "5                1996 Suzuki Alto   US$1,994                   \n",
      "\n",
      "                                          Car Images  \\\n",
      "0  https://www.tc-v.com/cdn/trade/img06/cars/3147...   \n",
      "1  https://www.tc-v.com/cdn/trade/img06/cars/3147...   \n",
      "2  https://www.tc-v.com/cdn/trade/img06/cars/3147...   \n",
      "3  https://www.tc-v.com/cdn/trade/img06/cars/3147...   \n",
      "4  https://www.tc-v.com/cdn/trade/img06/cars/3147...   \n",
      "5  https://www.tc-v.com/cdn/trade/img06/cars/3147...   \n",
      "\n",
      "                                        Car Features  \\\n",
      "0  64,084 km | Automatic | - | Gasoline/Petrol | ...   \n",
      "1  64,084 km | Automatic | - | Gasoline/Petrol | ...   \n",
      "2  64,084 km | Automatic | - | Gasoline/Petrol | ...   \n",
      "3  64,084 km | Automatic | - | Gasoline/Petrol | ...   \n",
      "4  64,084 km | Automatic | - | Gasoline/Petrol | ...   \n",
      "5  64,084 km | Automatic | - | Gasoline/Petrol | ...   \n",
      "\n",
      "       VIN(Vehicle Identification Number)/Serial No.  \\\n",
      "0  WBAUE12090PC76***Full VIN/Serial No. will be s...   \n",
      "1  TRJ120-5078***Full VIN/Serial No. will be show...   \n",
      "2  TRJ120-5068***Full VIN/Serial No. will be show...   \n",
      "3  DE3FS-145***Full VIN/Serial No. will be shown ...   \n",
      "4  WBAVL92070VU22***Full VIN/Serial No. will be s...   \n",
      "5  ---***Full VIN/Serial No. will be shown on Pro...   \n",
      "\n",
      "                            Model Code Registration Year / Month  \\\n",
      "0                                    -                      2007   \n",
      "1                          CBA-TRJ120W                      2007   \n",
      "2                          CBA-TRJ120W                      2007   \n",
      "3                                DE3FS                   2008/04   \n",
      "4  BMW X1 SDRIVE20I AT D/AB HID SR NAV                   2013/02   \n",
      "5                                    -                      1996   \n",
      "\n",
      "  Manufacture Year / Month     Mileage  ...    Drive Type Door  \\\n",
      "0  Confirm with the Seller   64,084 km  ...             -    5   \n",
      "1                     2007   72,378 km  ...  4wheel drive    5   \n",
      "2                     2007  102,656 km  ...  4wheel drive    5   \n",
      "3  Confirm with the Seller    5,000 km  ...  2wheel drive    5   \n",
      "4                     2012   64,425 km  ...  2wheel drive    5   \n",
      "5  Confirm with the Seller   26,000 km  ...             -    3   \n",
      "\n",
      "  Number of Seats                  Dimension           Condition  \\\n",
      "0               5                          -                Used   \n",
      "1               5  472cm×188cm×191cm=16.95m³                Used   \n",
      "2               8  472cm×188cm×191cm=16.95m³                Used   \n",
      "3               5   390cm×170cm×148cm=9.81m³                Used   \n",
      "4               5  445cm×204cm×154cm=13.98m³  Used (No Accident)   \n",
      "5               4                          -                Used   \n",
      "\n",
      "                             ID Remarks (Any Problems)  \\\n",
      "0   3147874-KRM12790-12793-289R                      -   \n",
      "1          3124746-220621200516                      -   \n",
      "2          3124746-230209102148                      -   \n",
      "3  3250454-3255531-230214145800                      -   \n",
      "4  3173992-3226545-230224164115                      -   \n",
      "5    3147874-KRM26508-26516-25R                      -   \n",
      "\n",
      "                                             Comment            Expiry Date  \\\n",
      "0                                                  -  Aug / 27 / 2023 (JST)   \n",
      "1                                                  -  Jun / 02 / 2023 (JST)   \n",
      "2  Looks & runs great\\nVery clean interior\\nRuns ...  Jun / 14 / 2023 (JST)   \n",
      "3                                                  -  Jun / 23 / 2023 (JST)   \n",
      "4  Must see\\nVery clean interior\\nLooks & runs gr...  Jun / 14 / 2023 (JST)   \n",
      "5                                                  -  Aug / 23 / 2023 (JST)   \n",
      "\n",
      "                                         Car Options  \n",
      "0  Driver Airbag | Anti-Lock Brakes | Passenger A...  \n",
      "1  Driver Airbag | Anti-Lock Brakes | Passenger A...  \n",
      "2  Driver Airbag | Anti-Lock Brakes | Passenger A...  \n",
      "3  Driver Airbag | Anti-Lock Brakes | Passenger A...  \n",
      "4  Driver Airbag | Anti-Lock Brakes | Passenger A...  \n",
      "5  Driver Airbag | Anti-Lock Brakes | Passenger A...  \n",
      "\n",
      "[6 rows x 28 columns]\n",
      "Got these many results: (6, 28)\n",
      "Data has been scraped and saved to CSV file\n"
     ]
    }
   ],
   "source": [
    "# List of URLs to scrape\n",
    "urls = [\n",
    "    \"https://www.tc-v.com/used_car/bmw/1%20series/33693276/?isNew=1\",\n",
    "    \"https://www.tc-v.com/used_car/toyota/land%20cruiser%20prado/32929679/?isNew=1\",\n",
    "    \"https://www.tc-v.com/used_car/toyota/land%20cruiser%20prado/32668631/?isNew=1\",\n",
    "    \"https://www.tc-v.com/used_car/mazda/demio/32738225/?isNew=1\",\n",
    "    \"https://www.tc-v.com/used_car/bmw/x1/33633147/?isNew=1\",\n",
    "    \"https://www.tc-v.com/used_car/suzuki/alto/32236783/?isNew=1\",\n",
    "]\n",
    "\n",
    "# Create an empty list to store the scraped data\n",
    "all_data = []\n",
    "images = []\n",
    "stock_specific_information = []\n",
    "title_labels = []\n",
    "title_values = []\n",
    "options_key_values = []\n",
    "options_value_values = []\n",
    "features_info = []\n",
    "car_names = []\n",
    "car_fob_price = []\n",
    "car_estimated_price = []\n",
    "\n",
    "# Iterate over each URL\n",
    "for url in urls:\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Create a BeautifulSoup object to parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Scrape car title\n",
    "    car_title = soup.find(\"h1\", class_=\"car__detail-ttl\").text.strip()\n",
    "    car_names.append(car_title)\n",
    "\n",
    "    # Scrape features under title\n",
    "    cars_feature = soup.select(\".car__detail-tag-item\")\n",
    "    for features in cars_feature:\n",
    "        feature = features.text.strip()\n",
    "        features_info.append(feature)\n",
    "\n",
    "    # Scrape car price\n",
    "    car_price = soup.find(\"div\", class_=\"car__price-body\").text.strip()\n",
    "    car_fob_price.append(car_price)\n",
    "\n",
    "    # Scrape car estimate total pricing\n",
    "    # car_price_estimated = soup.find(\n",
    "    #     \"span\", attrs={\"data-car-target\": \"displayTotalPriceEl\"}\n",
    "    # )\n",
    "    car_total_price = soup.find(\n",
    "        \"span\", attrs={\"data-car-target\": \"displayTotalPriceEl\"}\n",
    "    ).text.strip()\n",
    "\n",
    "    print(\"Estimated\", car_total_price)\n",
    "    car_estimated_price.append(car_total_price)\n",
    "\n",
    "    # Scrape car images\n",
    "\n",
    "    image_elements = soup.find_all(\"div\", class_=\"car__detail-main-area\")\n",
    "\n",
    "    for getImages in image_elements:\n",
    "        getImage = getImages.find_all(\"img\", src=True)\n",
    "        for imageUrl in getImage:\n",
    "            images.append(imageUrl[\"src\"])\n",
    "\n",
    "    # Scrape stock-specific information\n",
    "    info_elements = soup.find_all(\"li\", class_=\"detail__list-item\")\n",
    "    for info_element in info_elements:\n",
    "        info_text = info_element.text.strip()\n",
    "        stock_specific_information.append(info_text)\n",
    "\n",
    "    # Scrape title labels and values\n",
    "    title_elements = soup.find_all(\"th\", class_=\"car__info-table-ttl\")\n",
    "    for title_element in title_elements:\n",
    "        title_text = title_element.text.strip()\n",
    "        title_labels.append(title_text)\n",
    "\n",
    "    value_elements = soup.find_all(\"td\", class_=\"car__info-table-body\")\n",
    "    for value_element in value_elements:\n",
    "        value_text = value_element.text.strip()\n",
    "        title_values.append(value_text)\n",
    "\n",
    "    # Scrape car options\n",
    "    options_elements = soup.find_all(\"dt\", class_=\"option__item-ttl\")\n",
    "    for option_element in options_elements:\n",
    "        option_text = option_element.text.strip()\n",
    "        options_key_values.append(option_text)\n",
    "\n",
    "    values_elements = soup.find_all(\"dd\", class_=\"option__item\")\n",
    "    for value_element in values_elements:\n",
    "        value_text = value_element.text.strip()\n",
    "        options_value_values.append(value_text)\n",
    "\n",
    "    # Remove square brackets and single quotes from the scraped data\n",
    "    car_title = re.sub(r\"[\\[\\]']\", \"\", car_title)\n",
    "    car_price = re.sub(r\"[\\[\\]']\", \"\", car_price)\n",
    "    images = [re.sub(r\"[\\[\\]']\", \"\", image) for image in images]\n",
    "    stock_specific_information = [\n",
    "        re.sub(r\"[\\[\\]']\", \"\", info) for info in stock_specific_information\n",
    "    ]\n",
    "    title_labels = [re.sub(r\"[\\[\\]']\", \"\", label) for label in title_labels]\n",
    "    title_values = [re.sub(r\"[\\[\\]']\", \"\", value) for value in title_values]\n",
    "    options_key_values = [\n",
    "        re.sub(r\"[\\[\\]']\", \"\", option) for option in options_key_values\n",
    "    ]\n",
    "    options_value_values = [\n",
    "        re.sub(r\"[\\[\\]']\", \"\", option) for option in options_value_values\n",
    "    ]\n",
    "\n",
    "    # Create separate lists for each key in the data dictionary\n",
    "    car_titles = [car_title]\n",
    "    car_prices = [car_price]\n",
    "    car_images = [\" | \".join(images)]\n",
    "    stock_specific_info_lists = {\n",
    "        label: value * len(car_titles)\n",
    "        for label, value in zip(title_labels, title_values)\n",
    "    }\n",
    "    car_option_lists = [\" | \".join(options_value_values)]\n",
    "\n",
    "    # Create a dictionary for the scraped data from the current URL\n",
    "    data = {\n",
    "        \"Car Title\": car_title,\n",
    "        \"Car Price\": car_price,\n",
    "        \"Car Total Price\": car_total_price,\n",
    "        \"Car Images\": \" | \".join(images),\n",
    "        \"Car Features\": \" | \".join(features_info),\n",
    "        **stock_specific_info_lists,\n",
    "        \"Car Options\": \" | \".join(options_value_values),\n",
    "    }\n",
    "\n",
    "    # Append the data to the list of all data\n",
    "    all_data.append(data)\n",
    "\n",
    "    # Add a 1-minute delay between each URL scrape\n",
    "    time.sleep(5)\n",
    "\n",
    "# Create a DataFrame from the list of all data\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "print(df)\n",
    "print(\"Got these many results:\", df.shape)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "currentDateTime = datetime.now().strftime(\"%m-%d-%Y-%H-%M-%S-%p\")\n",
    "df.to_csv(f\"tc-v-{currentDateTime}.csv\", index=False)\n",
    "print(\"Data has been scraped and saved to CSV file\")\n",
    "\n",
    "# Add a delay\n",
    "time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c72e032",
   "metadata": {},
   "source": [
    "## Beforward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f53e272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$880\n",
      "$2,225\n",
      "Car Title: 2014 VOLKSWAGEN UP!\n",
      "Car Price: $880\n",
      "Car Specifications:\n",
      "Ref. No.: BN467795\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# defining lists and variable\n",
    "stock_names = []\n",
    "stock_model_code = []\n",
    "stock_price = []\n",
    "stock_total_price = []\n",
    "stock_images = []\n",
    "stock_features = []\n",
    "stock_specifications = []\n",
    "stock_features_list = []\n",
    "stock_highlights_list = []\n",
    "# Create a dictionary to store car specifications\n",
    "car_specifications = {}\n",
    "\n",
    "# URL of the web page to scrape\n",
    "url = \"https://www.beforward.jp/volkswagen/up-/bn467795/id/4926174/\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Create a BeautifulSoup object to parse the HTML content\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Scrape car title\n",
    "car_title = soup.find_all(\"h1\")[1].text.strip()\n",
    "\n",
    "# Car Price\n",
    "car_price = soup.find(\"span\", class_=\"price ip-usd-price\").text.strip()\n",
    "print(car_price)\n",
    "stock_price.append(car_price)\n",
    "car_total_price = soup.find(\"p\", \"total-price\").text.strip()\n",
    "print(car_total_price)\n",
    "stock_total_price.append(car_total_price)\n",
    "\n",
    "# Feature List\n",
    "car_feature_list = soup.find_all(\"div\", class_=\"remarks\")\n",
    "for feature_list in car_feature_list:\n",
    "    feature_detail = feature_list.find_all(\"ul\")\n",
    "    for features in feature_detail:\n",
    "        feature = features.find(\"li\").text\n",
    "        stock_features_list.append(feature)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "car_specification_title = []\n",
    "car_specification_value = []\n",
    "car_specification = soup.find_all(\"table\", class_=\"specification\")\n",
    "for title_elements in car_specification:\n",
    "    label = title_elements.find(\"th\", class_=\"gray\").text.strip()\n",
    "    value = title_elements.find(\"td\").text.strip()\n",
    "    car_specifications[label] = value\n",
    "\n",
    "# Print the scraped data\n",
    "print(\"Car Title:\", car_title)\n",
    "print(\"Car Price:\", car_price)\n",
    "print(\"Car Specifications:\")\n",
    "for label, value in car_specifications.items():\n",
    "    print(label + \":\", value)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dcc592a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car Title: 2014 VOLKSWAGEN UP!\n",
      "Car Price: $880\n",
      "Car Specifications:\n",
      "Ref. No.: BN467795\n",
      "Chassis No.: WVWZZZAAZED064256\n",
      "Model Code: DBA-AACHY\n",
      "Engine Size: 990cc\n",
      "Location: KYUSHU\n",
      "Version/Class: \n",
      "Drive: -\n",
      "Transmission: Automatic\n",
      "RegistrationYear/month: 2014/3\n",
      "ManufactureYear/month: N/A\n",
      "Max.Cap: -\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# defining lists and variable\n",
    "stock_names = []\n",
    "stock_model_code = []\n",
    "stock_price = []\n",
    "stock_total_price = []\n",
    "stock_images = []\n",
    "stock_features = []\n",
    "stock_specifications = []\n",
    "stock_features_list = []\n",
    "stock_highlights_list = []\n",
    "# Create a dictionary to store car specifications\n",
    "car_specifications = {}\n",
    "\n",
    "# URL of the web page to scrape\n",
    "url = \"https://www.beforward.jp/volkswagen/up-/bn467795/id/4926174/\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Create a BeautifulSoup object to parse the HTML content\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Scrape car title\n",
    "car_title = soup.find_all(\"h1\")[1].text.strip()\n",
    "\n",
    "# Car Price\n",
    "car_price = soup.find(\"span\", class_=\"price ip-usd-price\").text.strip()\n",
    "stock_price.append(car_price)\n",
    "\n",
    "car_total_price = soup.find(\"p\", \"total-price\").text.strip()\n",
    "stock_total_price.append(car_total_price)\n",
    "\n",
    "# Feature List\n",
    "car_feature_list = soup.find_all(\"div\", class_=\"remarks\")\n",
    "for feature_list in car_feature_list:\n",
    "    feature_detail = feature_list.find_all(\"ul\")\n",
    "    for features in feature_detail:\n",
    "        feature = features.find(\"li\").text\n",
    "        stock_features_list.append(feature)\n",
    "\n",
    "# Car Specifications\n",
    "car_specification_title = []\n",
    "car_specification_value = []\n",
    "car_specification = soup.find_all(\"table\", class_=\"specification\")\n",
    "for table in car_specification:\n",
    "    rows = table.find_all(\"tr\")\n",
    "    for row in rows:\n",
    "        title = row.find(\"th\").text.strip()\n",
    "        value = row.find(\"td\").text.strip()\n",
    "        car_specifications[title] = value\n",
    "\n",
    "# Print the scraped data\n",
    "print(\"Car Title:\", car_title)\n",
    "print(\"Car Price:\", car_price)\n",
    "print(\"Car Specifications:\")\n",
    "for label, value in car_specifications.items():\n",
    "    print(label + \":\", value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1578cf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Car Title': ['2014 VOLKSWAGEN UP! HIGH UP!'], 'Model Code': ['DBA-AACHY BN513752'], 'Car Price': ['$3,430'], 'Car Total Price': ['$4,392'], 'Car Images': [], 'Car Features': ['CD Player | Power Steering | Airbag | TV | Rear Spoiler | Wheel Spanner | Keyless Entry | Side Airbag | Navigation'], 'Car Specifications': [{'Ref. No.': 'BN513752', 'Chassis No.': 'WVWZZZAAZED102459', 'Model Code': 'DBA-AACHY', 'Engine Size': '1,000cc', 'Location': 'NAGOYA', 'Version/Class': 'high up!', 'Drive': '2wheel drive', 'Transmission': 'Automatic', 'RegistrationYear/month': '2014/4', 'ManufactureYear/month': 'N/A', 'Max.Cap': '-', 'Sub Ref No': 'CSD2304180026'}], 'Car Highlights': ['']}\n"
     ]
    }
   ],
   "source": [
    "# defining lists and variables\n",
    "stock_names = []\n",
    "stock_model_code = []\n",
    "stock_price = []\n",
    "stock_total_price = []\n",
    "stock_images = []\n",
    "stock_features = []\n",
    "stock_specifications = []\n",
    "stock_features_list = []\n",
    "stock_highlights_list = []\n",
    "# Create a dictionary to store car specifications\n",
    "car_specifications = {}\n",
    "\n",
    "# URL of the web page to scrape\n",
    "url = \"https://www.beforward.jp/volkswagen/up-/bn513752/id/4965525/\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Create a BeautifulSoup object to parse the HTML content\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Scrape car title\n",
    "car_title = soup.find_all(\"h1\")[1].text.strip()\n",
    "\n",
    "# Car Price\n",
    "car_price = soup.find(\"span\", class_=\"price ip-usd-price\").text.strip()\n",
    "stock_price.append(car_price)\n",
    "\n",
    "car_total_price = soup.find(\"p\", \"total-price\").text.strip()\n",
    "stock_total_price.append(car_total_price)\n",
    "\n",
    "# car SKU\n",
    "try:\n",
    "    car_sku = soup.find(\"div\", class_=\"detail-specs-text\").text.strip()\n",
    "    stock_model_code.append(car_sku)\n",
    "except:\n",
    "    car_sku = \"None\"\n",
    "\n",
    "\n",
    "# Car Images\n",
    "car_image_elements = soup.find_all(\"a\", class_=\"thumb-item\")\n",
    "car_images = [image_element[\"href\"] for image_element in car_image_elements]\n",
    "stock_images.extend(car_images)\n",
    "\n",
    "# Feature List\n",
    "car_feature_list = soup.find_all(\"div\", class_=\"remarks\")\n",
    "for feature_list in car_feature_list:\n",
    "    feature_detail = feature_list.find_all(\"ul\")\n",
    "    for features in feature_detail:\n",
    "        feature = features.find(\"li\").text\n",
    "        stock_features_list.append(feature)\n",
    "\n",
    "# Car Specifications\n",
    "car_specification_title = []\n",
    "car_specification_value = []\n",
    "car_specification = soup.find_all(\"table\", class_=\"specification\")\n",
    "for table in car_specification:\n",
    "    rows = table.find_all(\"tr\")\n",
    "    for row in rows:\n",
    "        title = row.find(\"th\").text.strip()\n",
    "        value = row.find(\"td\").text.strip()\n",
    "        car_specifications[title] = value\n",
    "\n",
    "# Repeat values to match the length of other lists\n",
    "data_length = len(stock_price)\n",
    "stock_names = [car_title] * data_length\n",
    "stock_model_code = [car_sku] * data_length\n",
    "stock_features = [\" | \".join(stock_features_list)] * data_length\n",
    "stock_specifications = [car_specifications] * data_length\n",
    "stock_highlights_list = [\"\"] * data_length\n",
    "\n",
    "# Create a DataFrame from the scraped data\n",
    "data = {\n",
    "    \"Car Title\": stock_names,\n",
    "    \"Model Code\": stock_model_code,\n",
    "    \"Car Price\": stock_price,\n",
    "    \"Car Total Price\": stock_total_price,\n",
    "    \"Car Images\": stock_images,\n",
    "    \"Car Features\": stock_features,\n",
    "    \"Car Specifications\": stock_specifications,\n",
    "    \"Car Highlights\": stock_highlights_list,\n",
    "}\n",
    "print(data)\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# # Save the DataFrame to a CSV file\n",
    "# df.to_csv(\"beforward_dataset.csv\", index=False)\n",
    "\n",
    "# print(\"Data has been scraped and saved to car_data.csv.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b118b29",
   "metadata": {},
   "source": [
    "## Autocom Japan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33c161db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to car_data.csv\n"
     ]
    }
   ],
   "source": [
    "# URL of the web page to scrape\n",
    "url = \"https://autocj.co.jp/usedcar?stock=R00168798\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Create a BeautifulSoup object to parse the HTML content\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the stock title from the <h1> tag\n",
    "stock_title = soup.find(\"h1\").text.strip()\n",
    "\n",
    "# Find the <div> element with class \"vinfo\"\n",
    "vinfo_element = soup.find(\"div\", class_=\"vinfo\")\n",
    "\n",
    "# Find all <dt> and <dd> elements within the <div class=\"vinfo\">\n",
    "dt_elements = vinfo_element.find_all(\"dt\")\n",
    "dd_elements = vinfo_element.find_all(\"dd\")\n",
    "\n",
    "# Create lists to store the extracted data\n",
    "keys = []\n",
    "values = []\n",
    "\n",
    "# Iterate over the <dt> and <dd> elements and extract the data\n",
    "for dt, dd in zip(dt_elements, dd_elements):\n",
    "    dt_text = dt.text.strip()\n",
    "    dd_text = dd.text.strip()\n",
    "    keys.append(dt_text)\n",
    "    values.append(dd_text)\n",
    "\n",
    "# Create a dictionary from the extracted data\n",
    "car_data = {\"Stock Title\": stock_title}\n",
    "car_data.update(dict(zip(keys, values)))\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "df = pd.DataFrame([car_data])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_filename = \"car_data.csv\"\n",
    "df.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(\"Data saved to\", csv_filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "763294ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of URLs to scrape\n",
    "urls = [\n",
    "    \"https://autocj.co.jp/usedcar?stock=R00155019\",\n",
    "    \"https://autocj.co.jp/usedcar?stock=R00168798\"\n",
    "]\n",
    "\n",
    "# Create empty lists to store the scraped data\n",
    "all_data = []\n",
    "stock_titles = []\n",
    "\n",
    "# Iterate over each URL\n",
    "for url in urls:\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Create a BeautifulSoup object to parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Scrape the stock title (H1 tag)\n",
    "\n",
    "   # Scrape the stock title from the div with class 'car_title'\n",
    "    stock_title = soup.find(\"div\", class_=\"car_title\").find(\"h1\").text.strip()\n",
    "    stock_title = stock_title.replace(\"\\xa0\", \" \")  # Remove the 'Â' character\n",
    "    stock_titles.append(stock_title)\n",
    "\n",
    "    # Extract the meaningful data from the HTML\n",
    "    data = {}\n",
    "    dl_elements = soup.find_all(\"dl\")\n",
    "\n",
    "    for dl in dl_elements:\n",
    "        dt_elements = dl.find_all(\"dt\")\n",
    "        dd_elements = dl.find_all(\"dd\")\n",
    "\n",
    "        for dt, dd in zip(dt_elements, dd_elements):\n",
    "            dt_text = dt.text.strip()\n",
    "            dd_title = dd.get(\"title\", \"\")\n",
    "            data[dt_text] = dd_title\n",
    "\n",
    "    # Create a dictionary for the scraped data from the current URL\n",
    "    for title in stock_titles:\n",
    "        data[\"Stock Title\"] = title\n",
    "\n",
    "    # Append the data to the list of all data\n",
    "    all_data.append(data)\n",
    "\n",
    "# Create a DataFrame from the list of all data\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"autocj_co_jp_scraped_data.csv\", index=False)\n",
    "\n",
    "# Print the scraped stock titles\n",
    "# print(\"Stock Titles:\")\n",
    "# for title in stock_titles:\n",
    "#     print(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da4b83ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "2006          TOYOTA          PASSO                              X HID LIMITED\n"
     ]
    }
   ],
   "source": [
    "# URLs of the web page to scrape\n",
    "urls = \"https://www.picknbuy24.com/detail/?refno=0105000408\"\n",
    "\n",
    "# Site url\n",
    "site_url = \"https://www.picknbuy24.com\"\n",
    "\n",
    "# response\n",
    "response = requests.get(urls, headers=headers, timeout=5)\n",
    "print(response)\n",
    "\n",
    "# Add a delay\n",
    "time.sleep(6)\n",
    "\n",
    "page = BeautifulSoup(response.content, \"html.parser\")\n",
    "# print(page.prettify())\n",
    "\n",
    "# Stock page elements\n",
    "\n",
    "inquiry_elements = page.select(\"#inquiry\")\n",
    "inquiry_elements\n",
    "# stock title name\n",
    "for car_title in inquiry_elements:\n",
    "    title = car_title.find(\"h1\").text.strip()\n",
    "    title = title.replace(\"\\n\", \"\")\n",
    "    print(title)\n",
    "# print(car_title)\n",
    "# car_title = car_title.replace(\"\\xa0\", \" \")  # Remove the 'Â' character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a08a04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
